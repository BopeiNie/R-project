---
title: " Modern Data Mining: DataAquisition, Preparation and Visualization"
author:
- Bopei Nie
date: 'Jan. 29th, 2023'
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results = "hide", fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(ISLR, readxl, tidyverse, magrittr, dplyr, ggplot2, gridExtra, plotly)
# install.packages("png")
```


\pagebreak

# Overview

This is a fast-paced course that covers a lot of material. There will be a large amount of references. You may need to do your own research to fill in the gaps in between lectures and homework/projects. It is impossible to learn data science without getting your hands dirty. Please budget your time evenly. Last-minute work ethic will not work for this course. 

Homework in this course is different from your usual homework assignment as a typical student. Most of the time, they are built over real case studies.  While you will be applying methods covered in lectures, you will also find that extra teaching materials appear here.  The focus will be always on the goals of the study, the usefulness of the data gathered, and the limitations in any conclusions you may draw. Always try to challenge your data analysis in a critical way. Frequently, there are no unique solutions. 

Case studies in each homework can be listed as your data science projects (e.g. on your CV) where you see fit. 



## Objectives 

- Get familiar with `R-studio` and `RMarkdown`
- Hands-on R 
- Learn data science essentials 
    - gather data
    - clean data
    - summarize data 
    - display data
    - conclusion
- Packages
    - `dplyr`
    - `ggplot`

##  Instructions

- **Homework assignments can be done in a group consisting of up to three members**. Please find your group members as soon as possible and register your group on our Canvas site.

- **All work submitted should be completed in the R Markdown format.** You can find a cheat sheet for R Markdown [here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) For those who have never used it before, we urge you to start this homework as soon as possible. 

- **Submit the following files, one submission for each group:**  (1) Rmd file, (2) a compiled  HTML or pdf version, and (3) all necessary data files if different from our source data. You may directly edit this .rmd file to add your answers. If you intend to work on the problems separately within your group, compile your answers into one Rmd file before submitting. We encourage that you at least attempt each problem by yourself before working with your teammates. Additionally, ensure that you can 'knit' or compile your Rmd file. It is also likely that you need to configure Rstudio to properly convert files to PDF. [**These instructions**](http://kbroman.org/knitr_knutshell/pages/latex.html#converting-knitrlatex-to-pdf) might be helpful.

- In general, be as concise as possible while giving a fully complete answer to each question. All necessary datasets are available in this homework folder on Canvas. Make sure to document your code with comments (written on separate lines in a code chunk using a hashtag `#` before the comment) so the teaching fellows can follow along. R Markdown is particularly useful because it follows a 'stream of consciousness' approach: as you write code in a code chunk, make sure to explain what you are doing outside of the chunk. 

- A few good or solicited submissions will be used as sample solutions. When those are released, make sure to compare your answers and understand the solutions.


## Review materials

- Study Basic R Tutorial
- Study Advanced R Tutorial (to include `dplyr` and `ggplot`)
- Study lecture 1: Data Acquisition and EDA


# Case study 1: Audience Size

How successful is the Wharton Talk Show [Business Radio Powered by the Wharton School](https://businessradio.wharton.upenn.edu/)  


**Background:** Have you ever listened to [SiriusXM](https://www.siriusxm.com/)? Do you know there is a **Talk Show** run by Wharton professors in Sirius Radio?  Wharton launched a talk show called [Business Radio Powered by the Wharton School](https://businessradio.wharton.upenn.edu/) through the Sirius Radio station in January of 2014. Within a short period of time the general reaction seemed to be overwhelmingly positive. To find out the audience size for the show, we designed a survey and collected a data set via MTURK in May of 2014. Our goal was to **estimate the audience size**. There were 51.6 million Sirius Radio listeners then. One approach is to estimate the proportion of the Wharton listeners to that of the Sirius listeners, $p$, so that we will come up with an audience size estimate of approximately 51.6 million times $p$. 

To do so, we launched a survey via Amazon Mechanical Turk ([MTurk](https://www.mturk.com/)) on May 24, 2014 at an offered price of \$0.10 for each answered survey.  We set it to be run for 6 days with a target maximum sample size of 2000 as our goal. Most of the observations came in within the first two days. The main questions of interest are "Have you ever listened to Sirius Radio" and "Have you ever listened to Sirius Business Radio by Wharton?". A few demographic features used as control variables were also collected; these include Gender, Age and Household Income.  

We requested that only people in United States answer the questions. Each person can only fill in the questionnaire once to avoid duplicates. Aside from these restrictions, we opened the survey to everyone in MTurk with a hope that the sample would be more randomly chosen. 

The raw data is stored as `Survey_results_final.csv` on Canvas.

## Data preparation

1. We need to clean and select only the variables of interest. 

Select only the variables Age, Gender, Education Level, Household Income in 2013, Sirius Listener?, Wharton Listener? and Time used to finish the survey.

Change the variable names to be "age", "gender", "education", "income", "sirius", "wharton", "worktime".


We first read data from `Survey_results_final.csv`.
```{r read data, echo=TRUE, warning=FALSE}
survey <- read.csv("data/Survey_results_final.csv", header=T, stringsAsFactors = FALSE) 
```

Print existing columns names and select columns we want and rename them.
```{r, exam variable name, echo=TRUE, warning=FALSE}
names(survey)
```

```{r}
selectedsurvey <- 
  survey %>%
  select("Answer.Age","Answer.Gender","Answer.Education","Answer.HouseHoldIncome","Answer.Sirius.Radio", "Answer.Wharton.Radio","WorkTimeInSeconds")
```

```{r change name, echo=TRUE, warning=FALSE}
selectedsurvey <- selectedsurvey %>% rename(age = Answer.Age, gender = Answer.Gender, education = Answer.Education, income = Answer.HouseHoldIncome, 
                                            sirius = Answer.Sirius.Radio, wharton = Answer.Wharton.Radio, worktime = WorkTimeInSeconds) 
# change variable name and also update the data file
```

Then check the size of data and the basic summary. 
```{r, exam data, results='hide', echo=TRUE, warning=FALSE} 
str(selectedsurvey) # data format
summary(selectedsurvey) # quick summary. missing values may be shown
```


2. Handle missing/wrongly filled values of the selected variables

As in real world data with user input, the data is incomplete, with missing values, and has incorrect responses. There is no general rule for dealing with these problems beyond “use common sense.” In whatever case, explain what the problems were and how you addressed them. Be sure to explain your rationale for your chosen methods of handling issues with the data. Do not use Excel for this, however tempting it might be.

Tip: Reflect on the reasons for which data could be wrong or missing. How would you address each case? For this homework, if you are trying to predict missing values with regression, you are definitely overthinking. Keep it simple.


We first count the Null values. But found that there isn't missing values in our data. Then we move on to check if there is any data that could be wrong.
```{r, echo=TRUE, warning=FALSE} 
colSums(is.na(selectedsurvey))
```

We start with `age` and found that there are two values 'Eighteen (18)' and '27`' that can be transferred to the formalized character. There are 'female' and '' that don't contain any information. There are also age 4 and age 223 that are unreasonable. After checking the number of the rows, each value appears once. Since we have a large dataset with 1764 rows, we remove those rows directly. Additionally, since all the ages are numerical, we transform the data type of age from character to numeric.
```{r} 
unique(selectedsurvey$age)
```
```{r} 
sum(selectedsurvey$age == "female" | selectedsurvey$age == "")
```

```{r} 
cleanedsurvey <- selectedsurvey[!((selectedsurvey$age == "female")|(selectedsurvey$age == "")|(selectedsurvey$age == "4")|(selectedsurvey$age == "223")),]
```

```{r}
cleanedsurvey$age[cleanedsurvey$age == "Eighteen (18)"] <- "18"
cleanedsurvey$age[cleanedsurvey$age == "27`"] <- "27"
```

```{r}
cleanedsurvey$age <- as.numeric(as.character(cleanedsurvey$age))
```

```{r} 
unique(cleanedsurvey$age)
```

As for `gender`, we have 6 empty value in gender and we remove those rows directly.
```{r} 
unique(cleanedsurvey$gender)
```

```{r} 
sum(cleanedsurvey$gender == "")
```

```{r} 
cleanedsurvey <- cleanedsurvey[!(cleanedsurvey$gender == ""),]
```


`Education` in our case has seven values. There are `Other` and `select one` that don't contain any information. After counting the number of those two columns, we found there are 2 `Other` and 17 `select one`. We remove those 19 columns in our case. Additionally, the values are too long so that we simplify those values from `Bachelor’s degree or other 4-year degree` to `Bachelor` and `Some college, no diploma; or Associate’s degree` to `Some college`, etc.
```{r} 
unique(cleanedsurvey$education)
table(cleanedsurvey$education)
```

```{r} 
cleanedsurvey <- cleanedsurvey[!((cleanedsurvey$education == "Other")|(cleanedsurvey$education == "select one")),]
#unique(cleanedsurvey$education)
```

```{r} 
cleanedsurvey$education[cleanedsurvey$education == "Some college, no diploma; or Associate’s degree"] <- "3Some college"
cleanedsurvey$education[cleanedsurvey$education == "Graduate or professional degree"] <- "5Graduate"
cleanedsurvey$education[cleanedsurvey$education == "Bachelor’s degree or other 4-year degree"] <- "4Bachelor"
cleanedsurvey$education[cleanedsurvey$education == "High school graduate (or equivalent)"] <- "2High School"
cleanedsurvey$education[cleanedsurvey$education == "Less than 12 years; no high school diploma"] <- "1No High School"

unique(cleanedsurvey$education)
```

For `income`, we remove 5 empty rows and also simplify the values from `$30,000 - $50,000` to `$30k-$50k` for better plotting and reading.
```{r} 
unique(cleanedsurvey$income)
```
```{r} 
sum(cleanedsurvey$income == "")
```

```{r} 
cleanedsurvey <- cleanedsurvey[!(cleanedsurvey$income == ""),]
```

```{r} 
cleanedsurvey$income[cleanedsurvey$income == "$30,000 - $50,000"] <- "$30k-$50k"
cleanedsurvey$income[cleanedsurvey$income == "$15,000 - $30,000"] <- "$15k-$30k"
cleanedsurvey$income[cleanedsurvey$income == "$50,000 - $75,000"] <- "$50k-$75k"
cleanedsurvey$income[cleanedsurvey$income == "$75,000 - $150,000"] <- "$75k-$150k"
cleanedsurvey$income[cleanedsurvey$income == "Above $150,000"] <- "Above $150k"
cleanedsurvey$income[cleanedsurvey$income == "Less than $15,000"] <- "$0-$15k"

unique(cleanedsurvey$income)
```

For `sirius`, we remove 3 empty rows.
```{r} 
unique(cleanedsurvey$sirius)
```
```{r} 
sum(cleanedsurvey$sirius == "")
```

```{r} 
cleanedsurvey <- cleanedsurvey[!(cleanedsurvey$sirius == ""),]
```


For `wharton`, we remove 2 empty rows.
```{r} 
unique(cleanedsurvey$wharton)
```
```{r} 
sum(cleanedsurvey$wharton == "")
```

```{r} 
cleanedsurvey <- cleanedsurvey[!(cleanedsurvey$wharton == ""),]
```

`worktime` looks good in our case.
```{r} 
unique(cleanedsurvey$worktime)
```

Briefly speaking, we remove the entire rows with wrong or empty or meaningless values. We also simplify some complex values into more readable values.


3. Brief summary 

Write a brief report to summarize all the variables collected. Include both summary statistics (including sample size) and graphical displays such as histograms or bar charts where appropriate. Comment on what you have found from this sample. (For example - it's very interesting to think about why would one work for a job that pays only 10cents/each survey? Who are those survey workers? The answer may be interesting even if it may not directly relate to our goal.)

3.1 Brief summary
```{r}
str(cleanedsurvey)
summary(cleanedsurvey)
```
The sample size is 1744 after cleaning the missing and wrong values. We have in total 7 variables. Two numerical columns age and worktime and five categorical columns. For numerical column `age`, we have minimum age 18,  maximum age 76, mean age 30.4, and median age 28. For numerical column `worktime`, we have minimum 8, maximum 108, and mean 22.5. The other columns are categorical.

3.2 Basic demographic distributions:
The graph below shows the distribution of age:
```{r warning=FALSE}
ggplot(cleanedsurvey, aes(x = age)) + 
  geom_histogram(stat = "count", bins=10, fill = "blue") +
  labs( title = "Histogram of Age", x = "Age" , y = "Count") +
  theme(plot.title = element_text(hjust = 0.5))
```

The bar graph illustrates that the number of people increases significantly with age, reaching a peak and then decreasing sharply before tapering off gradually. The majority of the participants in the survey fall in the age range of 19 to 35, with a small percentage over 40 and only a limited number above 60. Although the group surveyed is relatively young, everyone is over the age of 18.

```{r warning=FALSE}
gender_counts <- table(cleanedsurvey$gender)
gender_percentages <- round(gender_counts / sum(gender_counts),4) * 100

ggplot(cleanedsurvey, aes(x = gender)) + 
  geom_histogram(stat = "count", fill = "blue") +
  labs( title = "Histogram of Gender", x = "Gender" , y = "Count")+
  theme(plot.title = element_text(hjust = 0.5))
```

Above plot is the gender distribution of our data that male accounts for more percentage than female. Females account for around 43% while males account for around 57%. More males take our survey.

```{r warning=FALSE}
ggplot(cleanedsurvey, aes(x = income)) + 
  geom_histogram(stat = "count", fill = "blue") +
  labs( title = "Histogram of Income", x = "Income" , y = "Count") +
  theme(plot.title = element_text(hjust = 0.5))
```

From the income distribution above, less people have household income above $150,000. The rest of income levels satisfy a normal distribution. The number of people with income ranging from 15,000 to 150,000 doesn't have significant difference. The plot make sense since the people with income above 150,000 don't need the 0.1 dollar per survey. Most of them may just take it for fun.

```{r}
#ggplot(cleanedsurvey, aes(x = education)) + 
  #geom_histogram(stat = "count", fill = "blue") +
  #labs( title = "Histogram of Education", x = "Education" , y = "Count")
```
```{r}
table(cleanedsurvey$education)
```

```{r}
edu_df <- data.frame(education = c("1No High School","2High School","3Some College","4Bachelor","5Graduate"),
                     count = c(10, 190, 737, 611, 177))

ggplot(as.data.frame(edu_df),
       aes(education, count)) +
  geom_bar(stat = "identity", fill="blue") +
  labs( title = "Histogram of Education", x = "Education" , y = "Count") +
  theme(plot.title = element_text(hjust = 0.5))
```

Most of the participants are in some college or bachelor's degree. Less participants are in graduate or high school graduate. Very few have no high school diploma. From this distribution, we can conclude that the participants are knowledgeable and most have received college education.

3.3 sirius and wharton percentage

3.3.1 percentage among the whole population
```{r}
counts <- as.data.frame(table(cleanedsurvey$sirius))

counts %<>% 
  rename(Sirius = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Sirius)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Sirius Percentage of Whole Sample")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  theme(plot.title = element_text(hjust = 0.5))
```

The above pie chart depicts the proportion of individuals who listen to Sirius among the entire sample population. There are 77% people in our sample listen to the sirius, which accounts for a large percentage.

```{r}
sirius_yes <- cleanedsurvey %>%
  filter(sirius == "Yes")

counts <- as.data.frame(table(sirius_yes$wharton))

counts %<>% 
  rename(Wharton = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Wharton)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Wharton Percentage of People Who Listen to Sirius")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  theme(plot.title = element_text(hjust = 0.5))
```

The above pie chart illustrated the proportion of individuals who listen to wharton among those who listen to sirius. There are only 5% sirius audience listen to wharton.

3.3.2 percentage group by demographics

Then we group by demographic information to check the proportion in each group:

```{r }
counts <- as.data.frame(table(cleanedsurvey$sirius, cleanedsurvey$gender))

counts %<>% 
  rename(Sirius = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Sirius)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Sirius Percentage by Gender")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ Var2)
```

Above graph shows the proportion of individuals who listen to Sirius among the entire sample population group by gender. The percentage shown here represents the proportion of individuals among the entire population including both males and females. More males (45%) listen to sirius compared with females (32%). But since the number of males is larger, there are also more males (13%) who don't listen to sirius than females (10%).

```{r }
counts <- as.data.frame(table(sirius_yes$wharton, sirius_yes$gender))

counts %<>% 
  rename(Wharton = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Wharton)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Wharton Percentage of Sirius by Gender")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ Var2)
```

Similar to what we got from proportion of sirius to the whole sample population. The numbers of males either listen to wharton among those listen to sirius or not listen to wharton are larger than the number of females.

```{r }
counts <- as.data.frame(table(cleanedsurvey$sirius, cleanedsurvey$education))

counts %<>% 
  rename(Sirius = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Sirius)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Sirius Percentage by Education Level")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ Var2)
```

From the pie chart above, more individuals in some college and bachelor listen to sirius. Graduate and high school have a small proportion listening to sirius while no high school almost have no people listen to sirius.

```{r }
counts <- as.data.frame(table(sirius_yes$wharton, sirius_yes$education))

counts %<>% 
  rename(Wharton = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Wharton)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Wharton Percentage of Sirius by Education Level")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  facet_wrap(~ Var2)
```

When coming to the proportion of wharton to sirius, the distribution spread evenly among high school, some college, bachelor, and graduate. We then draw another bar plot in the next section to show the detailed distribution below.


```{r }
counts <- as.data.frame(table(cleanedsurvey$sirius, cleanedsurvey$income))

counts %<>% 
  rename(Sirius = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Sirius)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Sirius Percentage by Income Level")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ Var2)
```

From the above pie chart, we can conclude that less people with income above 150k listen to sirius. That may because the sample number is small and the data is bias. Another reason may be those people are busy and don't have time to listen to sirius.

```{r }
counts <- as.data.frame(table(sirius_yes$wharton, sirius_yes$income))

counts %<>% 
  rename(Wharton = Var1)

ggplot(data = counts, aes(x = "", y = Freq, fill = Wharton)) + 
  geom_bar(width = 1, stat = "identity") + 
  coord_polar("y", start = 0) + 
  ggtitle("Wharton Percentage of Sirius by Income Level")+
  geom_text(aes(label = paste(round(Freq/sum(Freq)*100),"%")), position = position_stack(vjust = 0.5)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~ Var2)
```

When coming to the proportion of wharton to sirius, the distribution spread evenly among income from 0 to 150k. We then draw another bar plot in the next section to show the detailed distribution below.

3.3.3 wharton audience distribution

```{r warning=FALSE}
wharton_yes <- cleanedsurvey %>%
  filter(sirius == "Yes" & wharton == "Yes")

ggplot(wharton_yes, aes(x = education)) + 
  geom_histogram(stat = "count", fill = "blue") +
  labs( title = "Histogram of Education", x = "Education" , y = "Count") +
  theme(plot.title = element_text(hjust = 0.5))
```

More some college and bachelor individuals listen to wharton radio. There is no `no High School` listen to it. We can conclude that people who listen to wharton radio are well-educated.


```{r warning=FALSE}
ggplot(wharton_yes, aes(x = income)) + 
  geom_histogram(stat = "count", fill = "blue") +
  labs( title = "Histogram of Income", x = "Income" , y = "Count") +
  theme(plot.title = element_text(hjust = 0.5))
```

More individuals with income from 50k to 150k listen to the wharton radio while seldom of those with above 150k listen to the wharton radio.


```{r warning=FALSE}
ggplot(wharton_yes, aes(x = age)) + 
  geom_histogram(stat = "count", fill = "blue") +
  labs( title = "Histogram of Age", x = "Age" , y = "Count") +
  theme(plot.title = element_text(hjust = 0.5))
```

More individuals aging from 20 to 30 listen to wharton audio. 

The overall trend of wharton audience distribution is similar to the sample's distribution.

## Sample properties

The population from which the sample is drawn determines where the results of our analysis can be applied or generalized. We include some basic demographic information for the purpose of identifying sample bias, if any exists. Combine our data and the general population distribution in age, gender and income to try to characterize our sample on hand.

1. Does this sample appear to be a random sample from the general population of the USA?

2. Does this sample appear to be a random sample from the MTURK population?

Note: You can not provide evidence by simply looking at our data here. For example, you need to find distribution of education in our age group in US to see if the two groups match in distribution. You may need to gather some background information about the MTURK population to have a slight sense if this particular sample seem to a random sample from there... Please do not spend too much time gathering evidence. 

### age

We have minimum age 18,  maximum age 76, mean age 30.4, and median age 28 from the summarized data as well as the distribution of each age. We then check the distribution of age in the 2014 United States and Mturk.

```{r}
# install.packages("png")

library(png)
img <- readPNG("graph/age_distribution_USCB.png")

library(ggplot2)
library(grid)

ggplot() + 
  annotation_custom(rasterGrob(img, width = unit(1, "npc"), height = unit(1, "npc")))
```

The above chart is drawn from the tables on [United States Census Bureau website](https://www.census.gov/data/tables/2014/demo/age-and-sex/2014-age-sex-composition.html). The [table](https://www2.census.gov/programs-surveys/demo/tables/age-and-sex/2014/age-sex-composition/2014gender_table1.xlsx) has detailed data on age and gender distribution. As we could see from this chart, the total number of people age from 20-59 have even distribution that around 20,000. It is different from our data with an obvious peak. Besides, the median age is 37.6, which is higher than the data we have.

```{r}
img <- readPNG("graph/age_Mturk.png")
ggplot() + 
  
  annotation_custom(rasterGrob(img, width = unit(1, "npc"), height = unit(1, "npc")))
```

```{r}
age_g1 <- nrow(cleanedsurvey %>% filter(age<=29))
age_g2 <- nrow(cleanedsurvey %>% filter(age %in% (30:49)))
age_g3 <- nrow(cleanedsurvey %>% filter(age %in% (50:64)))
age_g4 <- nrow(cleanedsurvey %>% filter(age>=65))

age_df <- data.frame(Age = c("18-29","30-49","50-64","65+"),
                     Count = c(age_g1,age_g2,age_g3,age_g4))

ggplot(as.data.frame(age_df),
       aes(Age, Count)) +
  geom_bar(stat = "identity", fill="blue") + 
  ggtitle("Age Distribution for our Mturk samples") +
  theme(plot.title = element_text(hjust = 0.5))
```

For the age distribution on MTURK, we plot the bar plot `Age Distribution (percentage) for All working adults and Workers on Mturk` from the data in the paper [Turkers in this canvassing: young, well-educated and frequent users](https://www.pewresearch.org/internet/2016/07/11/turkers-in-this-canvassing-young-well-educated-and-frequent-users/#:~:text=More%20than%20half%20of%20Turkers,high%20school%20degrees%20or%20less). We plot another age distribution based on our sample data according to the ranges in `Age Distribution for our Mturk samples`. People below 50 weight more than people above 50 in our case which is similar to the MTurk population. The population of Mturk workers from 18 to 50 account for a large percentage while in all working adults, the distribution satisfies a normal distribution. We also found that "Despite increased diversity, MTurk workers still look very little like the US population. MTurk workers are overwhelmingly young, with 70% of the MTurk population being below the age of 40, as compared to just 35% in the United States as a whole. Furthermore, there are very few participants above age 60 on MTurk." From Chandler, J., Rosenzweig, C., Moss, A.J. et al. Online panels in social science research: Expanding sampling methods beyond Mechanical Turk. Behav Res 51, 2022–2038 (2019). https://doi.org/10.3758/s13428-019-01273-7 [here](https://link.springer.com/article/10.3758/s13428-019-01273-7) The results from multiple articles correspond to what we drawn from our data. For example, most population are below 40 and median and mean are around 30. Very few people are above 60.

Thus, we can conclude that our data satisfies the MTURK population from the age's perspectives.

### gender
```{r}
img <- readPNG("graph/gender_distribution_USCB.png")
ggplot() + 
  annotation_custom(rasterGrob(img, width = unit(1, "npc"), height = unit(1, "npc")))
```

The data on the gender distribution in the US shows that males make up a higher percentage than females for ages below 29. For ages above 30, females make up a larger percentage than males. The data suggests that the majority of the population is between the ages of 19 and 35, and that the number of females is slightly more or similar to the number of males, which contradicts the overall trend in the data where males greatly outnumber females.

The blog, [The New New Demographics on Mechanical Turk: Is there Still a Gender Gap?](https://www.cloudresearch.com/resources/blog/the-new-new-demographics-on-mechanical-turk-is-there-still-a-gender-gap/), conduct research on the demographics of Mechanical Turk workers in 2013 and 2014. They reached results that 47% of Workers were female and over the last two years MTurk studies were more likely to have more male Workers by doing sample t-test. This result satisfies the gender distribution drawn from our data that male are more than female.

Thus, from the gender perspectives, our data more corresponds to MTurk's distribution.

### income
```{r}
img <- readPNG("graph/income_distribution_USCB.png")
ggplot() + 
  annotation_custom(rasterGrob(img, width = unit(1, "npc"), height = unit(1, "npc")))
```

This plot is drawn from the table in blog [Demographics of People on Amazon Mechanical Turk](https://www.cloudresearch.com/resources/blog/who-uses-amazon-mturk-2020-demographics/). Data are based on 2018 income. Compared with all working adults, the number of Mturk workers with income more than 150k is significantly smaller than CPS, which aligns with our dataset. The reason why number of people above $100k is far more than other ranges is because of the larger ranges 50k than 10k. The overall working adults income satisfy a normal distribution. More Mturks have household income ranging from 20k to 60k.  Our data roughly satisfies the Mturk's distribution.


### education
```{r}
img <- readPNG("graph/education_distribution.png")
ggplot() + 
  annotation_custom(rasterGrob(img, width = unit(1, "npc"), height = unit(1, "npc")))
```

Again from the paper [Turkers in this canvassing: young, well-educated and frequent users](https://www.pewresearch.org/internet/2016/07/11/turkers-in-this-canvassing-young-well-educated-and-frequent-users/#:~:text=More%20than%20half%20of%20Turkers,high%20school%20degrees%20or%20less), we can plot the above graph. As for all working adults, the population distribute evenly. However, Turkers who answered the Center’s online survey are more educated than working adults in general. More than half of Turkers (51%) report they have at least college degrees – much higher than the 36% of adult workers. Only 12% of Turkers report they have high school degrees or less. This result also satisfies our sample's education distribution.

In conclusion, from the perspectives of age, gender, income, and education, we can all reach the result that our sample appears to be a random sample from the MTURK population and the sample doesn't accord to the total population of United States.

## Final estimate

The goal of this study was to estimate the audience size of the Wharton Talk Show Business Radio Powered by the Wharton School, which was launched on Sirius Radio in January 2014. The data was gathered through a survey conducted on Amazon Mechanical Turk (MTurk) in May 2014, with a sample size of 1725 after cleaning. The survey asked participants if they had ever listened to Sirius Radio and if they had ever listened to the Sirius Business Radio by Wharton.

The estimation method used was to estimate the proportion of Wharton listeners to Sirius listeners in the MTURK population, and then multiply that proportion by the total number of Sirius Radio listeners in the United States, which was 51.6 million in January 2014.

```{r}
table(cleanedsurvey$sirius)
table(cleanedsurvey$wharton)

sirius_yes <- cleanedsurvey %>%
  filter(sirius == "Yes") 

sirius_no <- cleanedsurvey %>%
  filter(sirius == "No") 

table(sirius_yes$wharton)
table(sirius_no$wharton)
```
By filtering sirius and wharton columns, we will have the following data: among all 1725 participants, 1335 (77.39%) participants have listened to Sirius Radio and 69 (4%) participants have listened to Sirius Business Radio by Wharton. Among those 1335 participants who have listened to Sirius Radio, there are 67 (5.02%) participants have listened to Sirius Business Radio by Wharton. While there are two participants who have listened to Sirius Business Radio by Wharton but not listened to Sirius Radio. They are the wrong data in our dataset since wharton is a channel under sirius. Thus, we can estimate the proportion of Wharton listeners to Sirius listeners p as 0.0502. 

We assume that the sample is a random sample of the MTURK population, and that the proportion of Wharton listeners vs. Sirius listeners in the general population is the same as that in the MTURK population. We can then times 51.6 million audience size with p and get the estimated Wharton listeners size 2.59 million.

Limitations:
Firstly, The survey was conducted in May 2014, several months after the show was launched, which means that the audience size or the proportion of Wharton listeners vs. Sirius listeners may have changed. Additionally, the survey was only conducted on MTurk, which is not necessarily a representative sample of the general population. Though we assume that the proportion in the general population is the same as that in the MTURK population, we found lots of differences in age, gender, income, and education. So the results may not be generalizable to the entire population of Sirius Radio listeners.



## New task
Proposal:

We will first conduct a survey to estimate the audience size. The survey will estimate the proportion of number of people listening to Wharton Business Radio Show to the number of whole population. We can estimate the audience size through the estimated proportion times the whole population.

We can use Google Forms to conduct our survey. Everyone can only fill the form once and will get 50 cents after filling the form. It will be conducted randomly across the total U.S. population. The survey will ask whether they have listened to the Wharton Business Radio Show within the past month and their demographics (age, gender, education, income, etc.) to check the distribution. The survey will also ask how often they listen to the show, and how they discovered the show (e.g. through a friend, through a search engine, etc.). 50 cents could be paid for each survey ensure the quality of the survey and duplicates will be prevented. Our target survey number is 1800 but more are welcomed, which will cost $900 from the budget.

The survey will be advertised on social media platforms such as instagram, Facebook and Twitter. They have different target group. The more social media we reach, less bias the survey will have. The cost will be $100 on the advertisement.

The budget for this study is $1000. The cost of the online survey platform, advertising, and data analysis will be covered within this budget. We will conduct the survey for one month and a half and spend the last half month to analyze the data collected. The findings will be reported at the end of the second month.





# Case study 2: Women in Science


Are women underrepresented in science in general? How does gender relate to the type of educational degree pursued? Does the number of higher degrees increase over the years? In an attempt to answer these questions, we assembled a data set (`WomenData_06_16.xlsx`) from [NSF](https://ncses.nsf.gov/pubs/nsf19304/digest/field-of-degree-women) about various degrees granted in the U.S. from 2006 to 2016. It contains the following variables: Field (Non-science-engineering (`Non-S&E`) and sciences (`Computer sciences`, `Mathematics and statistics`, etc.)), Degree (`BS`, `MS`, `PhD`), Sex (`M`, `F`), Number of degrees granted, and Year.

Our goal is to answer the above questions only through EDA (Exploratory Data Analyses) without formal testing. We have provided sample R-codes in the appendix to help you if needed. 


## Data preparation  

1. Understand and clean the data

Notice the data came in as an Excel file. We need to use the package `readxl` and the function `read_excel()` to read the data `WomenData_06_16.xlsx` into R. 


a). Read the data into R.
```{r read_data, echo = TRUE, warning = FALSE}
raw_women <- read_excel("data/WomenData_06_16.xlsx")
names(raw_women)
head(raw_women)
```
b). Clean the names of each variables. (Change variable names to  `Field`,`Degree`, `Sex`, `Year` and `Number` )
```{r clean, echo = TRUE, warning = FALSE}
#change names
raw_women %<>% 
  rename(Field = 'Field and sex', Number = "Degrees Awarded")
```

c). Set the variable natures properly. 
```{r set, echo = TRUE, warning = FALSE}
# set the field, degree and sex as factors
raw_women %<>% 
  mutate( Field = as.factor(Field), Degree = as.factor(Degree), Sex = as.factor(Sex))
summary(raw_women)
```

d). Any missing values?

The data is of high quality and there isn't any missing values.
```{r missing, echo = TRUE, warning = FALSE}
colSums(is.na(raw_women))
```

2. Write a summary describing the data set provided here. 

a). How many fields are there in this data?

In this data set, there are 10 fields, including "Agricultural sciences", "Biological sciences", "Computer sciences", "Earth, atmospheric, and ocean sciences", "Mathematics and statistics", "Physical sciences", "Psychology", "Social sciences", "Engineering" and "Non-S&E". All the items above except the field "Non-S&E", are considered "S&E" fields.
```{r field, echo = TRUE, warning = FALSE}
raw_women %>% distinct(Field)
apply(raw_women, 2, function(x) length(unique(x)))
```
b). What are the degree types? 

In this context, there are three types of degrees: a Bachelor's degree (BS), a Master's degree (MS), and a Doctor of Philosophy (PhD).	
```{r degree, echo = TRUE, warning = FALSE}
raw_women %>% distinct(Degree)
```
c). How many year's statistics are being reported here? 

In this data set, statistics for 11 years are reported, with the earliest year being 2006 and the latest year being 2016.
```{r year, echo = TRUE, warning = FALSE}
apply(raw_women, 2, function(x) length(unique(x)))
raw_women %>%
  summarise(min_year = min(Year), max_year=max(Year))
```

## BS degrees in 2015

Is there evidence that more males are in science-related fields vs `Non-S&E`? Provide summary statistics and a plot which shows the number of people by gender and by field. Write a brief summary to describe your findings.

The data presents a breakdown of individuals' bachelor degrees in the fields of Science and Engineering (S&E) and non-S&E by gender in 2015. The total number of bachelor degrees in 2015 of non-S&E (1,266,072) is almost twice as the counterpart of S&E (650,057). 

Specifically, the 2015 data shows that 327,122 males and 322,935 females received bachelor degree in the S&E field, and 493,304 males and 772,768 females in the non-S&E field. The histogram demostrates that in S&E, the number of male is slightly greater than that of female, while in non-S&E, there are significantly more female than male. Besides, the number of both male and female granted bachelor degree in non-S&E are greater than the counterparts in S&E. 

Overall, this histogram illustrates the distribution granted bachelor degree in 2015 in different fields and genders, providing a clear visual representation of the data. 
```{r BS degrees in 2015, echo = FALSE, warning = FALSE,message=F}
raw_women %>%
  filter(Degree == "BS", Year == 2015) %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = SE, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 60)) +
  ggtitle("Degrees Granted by S&E/non-S&E by Gender")+
  labs(x = "Field", y = "Number (thousand)") +
  theme(plot.title = element_text(hjust = 0.5))
```

## EDA bringing type of degree, field and gender in 2015

Describe the number of people by type of degree, field, and gender. Do you see any evidence of gender effects over different types of degrees? Again, provide graphs to summarize your findings.

From this histogram, we can see that the number of people varies greatly by field and degree, and there are differences in the number of men and women in different fields and degrees. For example, there are more women than men in fields such as Psychology, Social Sciences and non-S&E with BS, MS and PhD degrees, but more men than women in fields such as Computer Science and Engineering. 

Besides, the gender gaps of PhD in Engineering, Mathematics and Statistics and Physical Sciences are wider than the counterparts of BS, while the gender gap of PhD in Social Science is narrower than that of BS.

Therefore, from the graph, we arrive in a conclusion that there is gender effect over different types of degrees. 
```{r EDA bringing type of degree, field and gender in 2015, echo =FALSE, warning = FALSE}
raw_women %>%
  filter(Year == 2015) %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Degree~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  ggtitle("Degrees Granted Across Fields by Degree and Gender")  +
  theme(plot.title = element_text(hjust = 0.5))
```

## EDA bring all variables 

In this last portion of the EDA, we ask you to provide evidence numerically and graphically: Do the number of  degrees change by gender, field, and time? 

The first graph illustrates the trend of female representation in non-S&E and S&E degrees from 2006 to 2016. In non-S&E, the proportion of females receiving a Master of Science (MS) degree is the highest among the degrees, with a stable proportion between 60% and 65% for both Bachelor of Science (BS) and MS degrees. However, the ratio of females receiving a Doctor of Philosophy (PhD) in non-S&E fluctuates during this period, with an overall trend of increasing from less than 60% to almost 65%.

In contrast, in S&E, the proportion of females receiving BS, MS, and PhD degrees is approximately 50%, 45%, and 42%, respectively, indicating an underrepresentation of females in MS and PhD degrees in S&E. Additionally, in 2016, there was a significant drop in the proportion of females receiving both MS and PhD degrees in S&E. Overall, the trends show that there is not an obvious improvement of gender ratio in all degrees in S&E during the decade, and even a widening of the gender gap in MS degrees.
```{r EDA bring all variables_1, echo = FALSE, warning = FALSE, message=FALSE}
# numeric
df_SE_women_num <- raw_women %>% 
  filter(Field != "Non-S&E") %>%
  group_by(Sex, Year) %>% summarise(val = sum(Number))

df_nonSE_women_num <- raw_women %>% 
  filter(Field == "Non-S&E") %>%
  group_by(Sex, Year) %>% summarise(val = sum(Number))

# plot
raw_women %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year, Degree) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  facet_grid(~Degree)+
  ggtitle("Female Proportion in Non-S&E/S&E Across Year by Degree") +
  labs(y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme(plot.title = element_text(hjust = 0.5))
```

From the second graph, we can observe that the number of degrees awarded does vary by gender, field, and time. The trend of number of degrees by gender shows that there is a greater increase in the number of non-S&E BS degrees awarded to females compared to males. However, there is a smaller increase in the number of S&E BS degrees awarded to females compared to males. As for the overall trend by field, the number of MS degrees in both non-S&E and S&E fields is increasing, while the number of PhD degrees in both fields remains stable from 2006 to 2016.
```{r EDA bring all variables_2, echo = FALSE, warning = FALSE, message=FALSE}
raw_women %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Number of Degrees Granted by Sex, Degree and Non-S&E/S&E") +
  labs(y = "Number") +
  theme(plot.title = element_text(hjust = 0.5))
```

Furthermore, as is shown in the third graph, the proportion of degrees awarded by gender across different degree levels and fields (non-S&E and S&E) remains relatively stable over the years. The male-to-female ratio for all degrees is around 0.4 in non-S&E, while in S&E, the ratio is greater than 0.5. This suggests that there is a greater proportion of males receiving degrees in S&E compared to females.
```{r EDA bring all variables_3, echo = FALSE, warning = FALSE, message=FALSE}
raw_women %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees Granted Proportion by Sex Across Degree and Non-S&E/S&E") +
  labs(y = "Proportion") +
  scale_y_continuous(labels = scales::percent) +
  theme(plot.title = element_text(hjust = 0.5))
```

## Women in Data Science

Finally, is there evidence showing that women are underrepresented in data science? Data science is an interdisciplinary field of computer science, math, and statistics. You may include year and/or degree.

There is evidence suggesting that women are underrepresented in Data Science. Since Data Science is an interdisciplinary field of Computer Science, Mathematics, and Statistics, it’s reasonable to assume that the people work in data science have a degree of Computer Science(CS) or Mathematics and Statistics(Math & Stats). Thus, we can observe the gender difference in data science by analyzing the data of CS and Math & Stats.

The histogram shows that the number of degrees granted to men in CS and Math & Stats is significantly higher than that of women, even with the gap widening over the years. This evidence suggests that there is a clear underrepresentation of women in data science, which is an interdisciplinary field that encompasses computer science, math, and statistics. This underrepresentation is a concern and needs to be addressed in order to promote diversity and inclusivity in the field of data science.
```{r Women in Data Science, echo = FALSE, warning = FALSE, message=FALSE}
raw_women %>%
  filter(Field %in% c("Computer sciences", "Mathematics and statistics")) %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Number of Degrees Granted in CS and Math & Stats by Sex Across Degree") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Final brief report

Summarize your findings focusing on answering the questions regarding if we see consistent patterns that more males pursue science-related fields. Any concerns with the data set? How could we improve on the study?

Based on the data analyzed in this study, in general, it appears that there is a consistent pattern of more males pursuing most of science-related fields. The number of males receiving degrees in Computer Science, Earth, Atmosphere, and Ocean Sciences, Engineering, Mathematics and Statistics and Physical Sciences are consistently greater than the counterparts of females from 2006 to 2016. What is worth noticing is that the gender gap is the largest in Computer Sciences bachelor degree, with the number of males being more than three times as females.
 
However, we should not ignore that in some science-related fields such as Agricultural Sciences, Biological Sciences, Psychology and Social Sciences, the number of females pursuing degrees are constantly larger than that of males.
```{r Final brief report, echo = FALSE, warning = FALSE}
raw_women %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Number of Degrees Granted by Sex Across Degree and Field") +
  theme(plot.title = element_text(hjust = 0.5))
```

Furthermore, Data Science, an interdisciplinary field of Computer Science, Mathematics, and Statistics, appears to have a significant gender gap with a much higher proportion of males receiving degrees in these areas.

As for concerns with the data set, it should be noted that the data is limited to the time period of 2006-2016 and may not accurately represent current trends. Also, the data only represents the the structure in the United States and the pattern may vary in other countries. Additionally, the data only includes information on degrees granted and does not take into account individuals who may have entered these fields through alternative means such as vocational training or on-the-job experience.

In order to improve upon this study, it would be beneficial to gather more recent data and to expand the scope of the analysis to include other factors such as race and socio-economic background. Besides, including data on individuals who entered the fields through alternative means could provide a more comprehensive understanding of the gender representation in these fields. Additionally, formal testing may improve the rigor and feasibility of the study.



# Case study 3: Major League Baseball

We would like to explore how payroll affects performance among Major League Baseball teams. The data is prepared in two formats record payroll, winning numbers/percentage by team from 1998 to 2014. 

Here are the datasets:

-`MLPayData_Total.csv`: wide format
-`baseball.csv`: long format

Feel free to use either dataset to address the problems. 

```{r, echo = TRUE, warning = FALSE}
# import datasets MLPayData_Total.csv and baseball.csv
datapay_wide <- read.csv("data/MLPayData_Total.csv", header=T, stringsAsFactors = FALSE)  
datapay_long <- read.csv("data/baseball.csv", header=T, stringsAsFactors = FALSE)  
```

```{r, echo = FALSE, warning = FALSE}
datapay_wide
```

```{r, echo = FALSE, warning = FALSE}
datapay_long
```

```{r, echo = TRUE, warning = FALSE}
# Change the column name Team.name.2014 to team
datapay_wide <- datapay_wide %>% rename(team = Team.name.2014)
```

## EDA: Relationship between payroll changes and performance

Payroll may relate to performance among ML Baseball teams. One possible argument is that what affects this year's performance is not this year's payroll, but the amount that payroll increased from last year. Let us look into this through EDA. 

Create increment in payroll

a). To describe the increment of payroll in each year there are several possible approaches. Take 2013 as an example:

    - option 1: diff: payroll_2013 - payroll_2012
    - option 2: log diff: log(payroll_2013) - log(payroll_2012)

Explain why the log difference is more appropriate in this setup.

- If A=1.1B, log(A)-log(B)=log(1.1)+log(B)-log(B)=log(1.1). Logarithmic scales can turn multiplicative relationship into an additive one, which are very useful for quantifying the relative change. Also, the calculation of log difference is symmetrical going forward and backward. The log difference in one direction is the additive inverse of the log difference in the other direction. 


b). Create a new variable `diff_log=log(payroll_2013) - log(payroll_2012)`. Hint: use `dplyr::lag()` function.

```{r Create new variables, echo = TRUE, warning = FALSE}
# Compute differences in payroll for each team each year
datapay_wide <-
  datapay_wide %>%
    mutate(diff_log_1999          = log(p1999) - log(p1998), 
         diff_log_2000          = log(p2000) - log(p1999), 
         diff_log_2001          = log(p2001) - log(p2000), 
         diff_log_2002          = log(p2002) - log(p2001),
         diff_log_2003          = log(p2003) - log(p2002),
         diff_log_2004          = log(p2004) - log(p2003),
         diff_log_2005          = log(p2005) - log(p2004),
         diff_log_2006          = log(p2006) - log(p2005),
         diff_log_2007          = log(p2007) - log(p2006),
         diff_log_2008          = log(p2008) - log(p2007),
         diff_log_2009          = log(p2009) - log(p2008),
         diff_log_2010          = log(p2010) - log(p2009),
         diff_log_2011          = log(p2011) - log(p2010),
         diff_log_2012          = log(p2012) - log(p2011),
         diff_log_2013          = log(p2013) - log(p2012),
         diff_log_2014          = log(p2014) - log(p2013)
         ) 
```

c). Create a long data table including: team, year, diff_log, win_pct

```{r, echo = TRUE, warning = FALSE, results="hold"}
diff_log <- datapay_wide %>%   # first create variable: diff_log and year
  select(team, diff_log_1999:diff_log_2014) %>% 
  pivot_longer(cols = starts_with("diff_log_"), 
               names_to = "year", 
               names_prefix = "diff_log_",
               values_to = "diff_log")
diff_log[1:3, 1:3] # show a few rows
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
win_pct <- datapay_wide %>%  # create variable: win_pct and year
  select(team, X1998.pct:X2014.pct) %>% 
  pivot_longer(cols = X1998.pct:X2014.pct,
               names_to = "year",
               names_prefix = "X", 
               values_to = "win_pct") %>%
  mutate(year = substr(year, 1, 4))
win_pct[1:3, 1:3]
```  


```{r, echo = TRUE, warning = FALSE, results="hold"}
# join tables into team, year, diff_log, win_pct
datapay_long2 <- diff_log %>% 
  inner_join(win_pct, by = c("team", "year"))

datapay_long2
```

## Exploratory questions

a). Which five teams had highest increase in their payroll between years 2010 and 2014, inclusive?

```{r, echo = TRUE, warning = FALSE, results="hold"}
# Find data of each team in 2010
payroll_2010<-
  datapay_long %>%
    filter(year == 2010) %>%
    rename(payroll_2010 = payroll)

payroll_2010
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
# Find data of each team in 2014 and merge with data in 2010
payroll_comb<-
  datapay_long %>%
    filter(year == 2014) %>%
    rename(payroll_2014 = payroll) %>%
    left_join(payroll_2010, by = "team") %>%
    mutate(payroll_diff=payroll_2014-payroll_2010) %>%
    arrange(desc(payroll_diff))

payroll_comb[1:5,]
```
- Through computing the raw differences of payrolls between 2010 and 2014 and arranging them from large to small, we concluded that the teams in the top five rows, Los Angeles Dodgers, Texas Rangers, Washington Nationals, Toronto Blue Jays, and San Francisco Giants, have the highest increase in payroll.

```{r, echo = TRUE, warning = FALSE, results="hold"}
# Find data of each team in 2010
datapay_long2_2010<-
  datapay_long2 %>%
    filter(year == 2010) %>%
    rename(diff_log_2010 = diff_log)

datapay_long2_2010
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
# Find data of each team in 2014 and merge with data in 2010
payroll_comb2<-
  datapay_long2 %>%
    filter(year == 2014) %>%
    rename(diff_log_2014 = diff_log) %>%
    left_join(datapay_long2_2010, by = "team") %>%
    mutate(payroll_diff=diff_log_2014-diff_log_2010) %>%
    arrange(desc(payroll_diff))

payroll_comb2[1:5,]
```
- Through computing the log differences of payrolls between 2010 and 2014 and arranging them from large to small, we discovered different results from using raw differences of payrolls. We concluded that the teams in the top five rows, Houston Astros, Oakland Athletics, Arizona Diamondbacks, San Diego Padres, and Texas Rangers, have the highest increase in payroll.

b). Between 2010 and 2014, inclusive, which team(s) "improved" the most? That is, had the biggest percentage gain in wins?

```{r, echo = TRUE, warning = FALSE, results="hold"}
improved<- payroll_comb %>%
    rename(win_2014 = win_num.x) %>%
    rename(win_2010 = win_num.y) %>%
    mutate(win_per_diff=(win_2014-win_2010)/win_2010) %>%
    arrange(desc(win_per_diff))

improved[1:3,]
```

- Pittsburgh Pirates has improved the most, with the percentage difference of wins being 0.544. 


## Do log increases in payroll imply better performance? 

Is there evidence to support the hypothesis that higher increases in payroll on the log scale lead to increased performance?

Pick up a few statistics, accompanied with some data visualization, to support your answer. 

```{r, echo = TRUE, warning = FALSE, results="hold"}
# Compute mean difference in payroll and mean winning percentage
datapay_long2 %>% group_by(team) %>%
  summarise(diff_payroll_mean = mean(diff_log),
            win_pct_mean = mean(win_pct)) %>%
  arrange(-diff_payroll_mean)
```

We arrange the mean difference in payroll in descending order. The accorded mean winning percentages, however, do not show a descending or ascending trend. Therefore, there is no obvious positive or negative correlation between these two variables judging from the table above. 

We continue to analyze if the difference in winning percentage could be related to difference in payroll. 

```{r, echo = TRUE, warning = FALSE, results="hold"}
# Compute differences in winning percentage for each team each year
datapay_wide <-
datapay_wide %>%
    mutate(diff_pct_1999          = X1999.pct - X1998.pct, 
         diff_pct_2000          = X2000.pct - X1999.pct,
         diff_pct_2001          = X2001.pct - X2000.pct,
         diff_pct_2002          = X2002.pct - X2001.pct,
         diff_pct_2003          = X2003.pct - X2002.pct,
         diff_pct_2004          = X2004.pct - X2003.pct,
         diff_pct_2005          = X2005.pct - X2004.pct,
         diff_pct_2006          = X2006.pct - X2005.pct,
         diff_pct_2007          = X2007.pct - X2006.pct,
         diff_pct_2008          = X2008.pct - X2007.pct,
         diff_pct_2009          = X2009.pct - X2008.pct,
         diff_pct_2010          = X2010.pct - X2009.pct,
         diff_pct_2011          = X2011.pct - X2010.pct,
         diff_pct_2012          = X2012.pct - X2011.pct,
         diff_pct_2013          = X2013.pct - X2012.pct,
         diff_pct_2014          = X2014.pct - X2013.pct
         ) 
```


```{r, echo = TRUE, warning = FALSE, results="hold"}
diff_log <- datapay_wide %>%   # first create variable: diff_log and year
  select(team, diff_log_1999:diff_log_2014) %>% 
  pivot_longer(cols = starts_with("diff_log_"), 
               names_to = "year", 
               names_prefix = "diff_log_",
               values_to = "diff_log")
diff_log[1:3, 1:3] # show a few rows

diff_win_pct <- datapay_wide %>%  # create variable: diff_win_pct and year
  select(team, diff_pct_1999:diff_pct_2014) %>% 
  pivot_longer(cols = diff_pct_1999:diff_pct_2014,
               names_to = "year",
               names_prefix = "diff_pct_", 
               values_to = "diff_win_pct") %>%
  mutate(year = substr(year, 1, 4))
diff_win_pct[1:3, 1:3]

# join tables into team, year, diff_log, diff_win_pct
datapay_long3 <- diff_log %>% 
  inner_join(diff_win_pct, by = c("team", "year")) 
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
datapay_long3
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
# Compute mean difference in payroll and mean difference in winning percentage
datapay_long3 %>% group_by(team) %>%
  summarise(diff_payroll_mean = mean(diff_log),
            diff_win_pct_mean = mean(diff_win_pct)*100) %>%
  arrange(-diff_payroll_mean)
```

After arranging the mean difference in payroll in descending order, we discovered that the difference in winning percentage stays quite constant: they are all very close to 0. But since winning percentages have small numbers, we time the means of each team by 100. The accorded differences in winning percentage still do not show a increasing or decreasing trend. These two variables do not show evidence of being related to each other. 

```{r, echo = TRUE, warning = FALSE, results="hold"}
summary(datapay_long3)
```
Looking at this table, we learned that the median and mean of winning percentage is 0. It seems like difference in winning percentage stays quite constant regardless of the difference in payroll. They do not seem to be related to each other. 

```{r, echo = TRUE, warning = FALSE, results="hold"}
# create total payroll and average winning percentage for each team
data_agg <-datapay_long2 %>% 
  group_by(team) %>%
  summarise(
    diff_payroll_total = sum(diff_log)/1000, 
    win_pct_ave = mean(win_pct))
str(data_agg)
summary(data_agg)
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
data_agg %>%
  ggplot(aes(x = diff_payroll_total, y = win_pct_ave)) + 
  geom_point(aes(color = team), size = 3) + 
  geom_smooth(method = "lm", formula = y ~ x, se = F,color = "red") + 
  geom_hline(aes(yintercept = mean(win_pct_ave)), color = "blue") +
  labs(title = "MLB Team's Overall Win vs. Payroll", 
       x = "Log Diff Payroll", 
       y = "Win_pct") +
  theme_bw() +
  theme(legend.position = "none")+
  theme(plot.title = element_text(hjust = 0.5))
  
```

The best fit line for average difference in payroll vs average winning percentage is almost a straight line. Average winning percentage keeps almost constant while the log difference in payroll changes. 
```{r set theme, echo = TRUE, warning = FALSE, results="hold"}
boxplot_theme <-
  theme_bw() +
  theme(legend.position = "none",
        plot.margin = margin(t = 5, r = 50, b = 5, l = 0, unit = "pt"), 
        axis.text.x = element_text(angle = -60, vjust = 0, hjust = 0),
        plot.title = element_text(hjust = 0.5))
# adjust for margins around the plot; t: top; r: right; b: bottom; l: left
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
# use reorder_within() and scale_x_reordered() from tidytext to order boxplot within each facet
datapay_long2 %>%
  ggplot(aes(x = forcats::fct_reorder(team, -win_pct, .fun = median), #order win_pct in a decreasing order
             y = win_pct, fill = team)) + 
  geom_boxplot() +
  xlab("Team") +
  ylab("Win_pct") +
  ggtitle("Winning Percentage by Team") +
  boxplot_theme
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
datapay_long2 %>%
  ggplot(aes(x = forcats::fct_reorder(team, -win_pct, .fun = median), #order win_pct in a decreasing order
             y = diff_log, fill = team)) + 
  geom_boxplot() +
  xlab("Team") +
  ylab("Log Diff Payroll") +
  ggtitle("Payroll by Team with Decreasing Winning Percentage") + 
  boxplot_theme
```


Again, while the winning percentage is in descending order, the accorded log difference in payroll, however, do not show a strong descending or ascending trend. We can see that the log difference in payroll for different teams are similar. It stays very close to 0. Therefore, there is no obvious correlation between winning percentage and log difference in payroll judging from the table above. 

After examining the overall payroll and winning percentage, we want to find out if time might plays a role in their relationships. We went on to use time series models. 

```{r, echo = TRUE, warning = FALSE, results="hold"}
# We used the time series model to monitor the relationship between difference in payroll and winning percentage vs. time.
plot1 <- datapay_long2 %>%
  ggplot(aes(x = year, y = diff_log, group = team, col = team)) + 
  geom_line() + 
  geom_point() +
  theme_bw() +
  ylab("Diff_log") +
  xlab("Year") +
ggtitle("Winning Percentage over Years") + 
  theme(plot.title = element_text(hjust = 0.5))

ggplotly(plot1 + 
           theme(legend.position = "none"))
```

Since the above plot shows too much information that is hard to capture, we decided to chose 4 teams to analyze. 

```{r, echo = TRUE, warning = FALSE, results="hold"}
selected_teams <- c("New York Yankees", "Boston Red Sox", "Oakland Athletics", "San Diego Padres")

plot2 <- datapay_long2 %>% 
  ggplot(aes(x = year, y = diff_log, group = team)) + 
  geom_line(col = "grey", alpha = .5) + 
  geom_point(col = "grey", alpha = .5) +
  geom_line(data = subset(datapay_long2, team %in% selected_teams),
            aes(col = team)) +
  geom_hline(aes(yintercept = 0), color = "blue") +
  geom_point(data = subset(datapay_long2, team %in% selected_teams),
            aes(col = team)) +  
  scale_color_manual(values = c("red", "darkblue", "orange", "purple")) +
  theme_bw() +
  xlab("Year")+
  ylab("Diff_log")+
  ggtitle("NY Yankees, Red Sox, Oakland A's, San Diego Padres") +
  theme(plot.title = element_text(hjust = 0.5))
ggplotly(plot2)
```

```{r, echo = TRUE, warning = FALSE, results="hold"}
plot3 <- datapay_long2 %>% 
  ggplot(aes(x = year, y = win_pct, group = team)) + 
  geom_line(col = "grey", alpha = .5) + 
  geom_point(col = "grey", alpha = .5) +
  geom_line(data = subset(datapay_long2, team %in% selected_teams),
            aes(col = team)) +
  geom_hline(aes(yintercept = 0.5), color = "blue") +
  geom_point(data = subset(datapay_long2, team %in% selected_teams),
            aes(col = team)) +  
  scale_color_manual(values = c("red", "darkblue", "orange", "purple")) +
  theme_bw() +
  xlab("Year")+
  ylab("Win_pct")+
  ggtitle("NY Yankees, Red Sox, Oakland A's, San Diego Padres") +
  theme(plot.title = element_text(hjust = 0.5))
ggplotly(plot3)
```

For the selected teams above, the trends of log difference in payroll vs. time seem to be unrelated to the trends of winning percentage vs. time.

```{r, echo = TRUE, warning = FALSE, results="hold"}
datapay_long2 %>%
  ggplot(aes(x=year, y=diff_log, group = team, color="red")) +
  geom_line()+
  geom_hline(aes(yintercept = 0), color = "grey", alpha = .5) +
  geom_hline(aes(yintercept = 0.5), color = "grey", alpha = .5) +
  geom_line(aes(x=year, y=win_pct, group = team, color="blue"))+
  labs(x="Year",y="Win_pct / Diff_log in payroll") +
  ggtitle("Stats by Teams")+
  facet_wrap(~team) + 
  theme_bw() +
  theme(legend.position = "none", 
        plot.title=element_text(hjust=0.5),
        plot.margin = margin(t = 5, r = 50, b = 5, l = 0, unit = "pt"), 
        axis.text.x = element_text(angle = -60, vjust = 0, hjust = 0))
        # adjust for margins around the plot; t: top; r: right; b: bottom; l: left
```

Now we observed the log difference in payroll and winning percentage over time for every team. The two lines does not seem to be going to the same direction or the opposite direction all the time. The trends of log difference in payroll vs. time seem to be unrelated to the trends of winning percentage vs. time.

In conclusion, difference in payroll is unrelated to performance or difference in performance. Higher increase in payroll does not lead to better performance. 

## Comparison

Which set of factors are better explaining performance? Yearly payroll or yearly increase in payroll? What criterion is being used? 

```{r, echo = TRUE, warning = FALSE, results="hold"}
data_agg2 <-datapay_long %>% 
  group_by(team) %>%
  summarise(
    payroll_total = sum(payroll)/1000, 
    win_pct_ave = mean(win_pct))
str(data_agg2)
summary(data_agg2)
```


```{r, echo = TRUE, warning = FALSE, results="hold"}
data_agg2 %>%
  ggplot(aes(x = payroll_total, y = win_pct_ave)) + 
  geom_point(aes(color = team), size = 3) + 
  geom_smooth(method = "lm", formula = y ~ x, se = F,color = "red") + 
  geom_hline(aes(yintercept = mean(win_pct_ave)), color = "blue") +
  labs(title = "MLB Team's Overall Winning percentage vs. Payroll", 
       x = "Payroll", 
       y = "Win_pct") +
  theme_bw() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) 
```
```{r, results="hold"}
data_agg %>%
  ggplot(aes(x = diff_payroll_total, y = win_pct_ave)) + 
  geom_point(aes(color = team), size = 3) + 
  geom_smooth(method = "lm", formula = y ~ x, se = F,color = "red") + 
  geom_hline(aes(yintercept = mean(win_pct_ave)), color = "blue") +
  labs(title = "MLB Team's Overall Win vs. Log Diff Payroll", 
       x = "Log Diff Payroll", 
       y = "Win_pct") +
  theme_bw() +
  theme(legend.position = "none",plot.title = element_text(hjust = 0.5))
```

We used the scatter plots and the best fit lines to compare payroll vs. win and log difference in payroll vs. win, since they are one of the best and the most direct way of visualizing data. From payroll vs. win, we see a positive correlation, meaning that as payroll grows, winning percentage grows as well. For the difference in payroll vs. win plot, we only see a constant line that is slightly negative. There is no strong correlations between increase in payroll and performance. 

```{r, echo = TRUE, warning = FALSE, results="hold"}
datapay_long %>%
  ggplot(aes(x=year, y=payroll, group = team, color="red")) +
  geom_line()+
  geom_line(aes(x=year, y=win_num, group = team, color="blue"))+
  labs(x="Year",y="Winning Number / Payroll") +
  ggtitle("Stats by Teams")+
  facet_wrap(~team) + 
  theme_bw() +
  theme(legend.position = "none", plot.title=element_text(hjust=0.5))
```

From this plot, we can also tell that payroll and winning number move in the same direction most of the time (increase together or decrease together). 

Therefore, from the plots we analyzed above, we concluded that yearly payroll is better at explaining performance than yearly increase in payroll. 